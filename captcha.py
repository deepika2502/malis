# -*- coding: utf-8 -*-
"""Captcha.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pyR_XFjpieicfsanr1zv2qz6wCW36bIC

# Download Files from Kaggle
"""
"""
from google.colab import drive
drive.mount('/content/drive')

!mkdir "/content/drive/My Drive/Colab Notebooks/captcha_ds"

!cd "/content/drive/My Drive/Colab Notebooks/captcha_ds"

!pip install -q kaggle

! mkdir ~/.kaggle

! cp kaggle.json ~/.kaggle/

! chmod 600 ~/.kaggle/kaggle.json

! kaggle datasets list

!pwd

!kaggle datasets download -d deepika2502/captchads

! mkdir captcha_ds

!pwd && ls

!mv "/content/captchads.zip" "/content/drive/MyDrive/Colab Notebooks/captcha_ds"

!rm -r captcha_ds

import zipfile
from google.colab import drive

drive.mount('/content/drive/')

zip_ref = zipfile.ZipFile("/content/drive/MyDrive/Colab Notebooks/captcha_ds/captchads.zip", 'r')
zip_ref.extractall("catpcha_ds")
zip_ref.close()

!python --version

#!pip list

!pip install flaml

"""

import tensorflow as tf
import glob
from tensorflow.keras.applications import EfficientNetB0
import numpy as np
import os
from sklearn.model_selection import train_test_split
from collections import Counter
from tqdm import tqdm
from skimage.io import imread
from sklearn.linear_model import SGDClassifier

import warnings
warnings.filterwarnings("ignore")

np.random.seed(202)

model = EfficientNetB0(weights='imagenet',include_top=False,
                       input_shape=(256,256,3))

"""# Read Files"""
import kagglehub

# Download latest version
path = kagglehub.dataset_download("deepika2502/captchads")

print("Path to dataset files:", path)
exit()
path = '/content/catpcha_ds/256x256/photo/tx_000000000000'
class_label= np.sort(os.listdir(path))
print(len(class_label), class_label)

"""# Prepare Data and Train - Classes 1-10"""

#Extract files from folder
def prepareNameWithLabels():
    X = []
    Y = []
    for i in tqdm(class_label[:10]):
        sourceFiles=os.listdir(os.path.join(path,i))
        for val in sourceFiles:
            img = imread(os.path.join(path,i, val))
            #img = resize(img, (256, 256, 3))
            X.append(img)
            Y.append(i)
    return X, Y

X,Y = prepareNameWithLabels()

X = np.asarray(X)
Y = np.asarray(Y)

print(X.shape, Y.shape, Y[:10])

print(Counter(Y), '\n')

X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X, Y,
                                                            test_size = 0.2,
                                                            stratify = Y,
                                                            random_state = 202)

print((Counter(y_train_1)), '\n')
print(Counter(y_test_1), '\n')

feature_extractor = model.predict(X_train_1)
shape = feature_extractor.shape
feature = feature_extractor.reshape(feature_extractor.shape[0],-1)

clf = SGDClassifier(random_state = 202, alpha=0.0001, learning_rate = "adaptive",
                    eta0=0.0001, max_iter = 6000, n_iter_no_change=5)
clf.partial_fit(feature, y_train_1, classes= class_label)
clf.score(feature,y_train_1)

test_features_extractor = model.predict(X_test_1)
test_feature = test_features_extractor.reshape(test_features_extractor.shape[0],-1)

predicted_output = clf.predict(test_feature)
from sklearn.metrics import classification_report
report = classification_report(y_test_1, predicted_output)
print(report)

import pickle

filename = 'finalized_model.sav'
pickle.dump(clf, open(filename, 'wb'))

loaded_model = pickle.load(open(filename, 'rb'))

test_features_extractor = model.predict(X_test_1)
test_feature = test_features_extractor.reshape(test_features_extractor.shape[0],-1)

predicted_output = loaded_model.predict(test_feature)
from sklearn.metrics import classification_report
report = classification_report(y_test_1, predicted_output)
print(report)

"""# Prepare data and train- Classes 11-20"""

X_2 = []
Y_2 = []
#Extract files from folder
def prepareNameWithLabels():
    for i in tqdm(class_label[10:20]):
        sourceFiles=os.listdir(os.path.join(path,i))
        for val in sourceFiles:
            img = imread(os.path.join(path,i, val))
            X_2.append(img)
            Y_2.append(i)

prepareNameWithLabels()

X_2 = np.asarray(X_2)
Y_2 = np.asarray(Y_2)

print(X_2.shape, Y_2.shape, Y_2[:10])

X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, Y_2,
                                                            test_size = 0.1,
                                                            stratify = Y_2,
                                                            random_state = 202)
import copy

X_train_d = copy.deepcopy(X_train_2)
y_train_d = copy.deepcopy(y_train_2)
np.random.seed(202)

for i in np.unique(y_train_1):
  idx = np.random.choice(np.where(y_train_1 == i)[0], 40, replace=False)
  X_train_d = np.concatenate([X_train_d, X_train_1[idx]])
  y_train_d = np.concatenate([y_train_d, y_train_1[idx]])

print(X_train_2.shape, X_train_d.shape)

X_test_d = np.concatenate([X_test_1, X_test_2])
y_test_d = np.concatenate([y_test_1, y_test_2])

feature_extractor = model.predict(X_train_d)
shape = feature_extractor.shape
feature = feature_extractor.reshape(feature_extractor.shape[0],-1)

clf.partial_fit(feature, y_train_d)
clf.score(feature,y_train_d)

test_features_extractor = model.predict(X_test_2)
test_feature = test_features_extractor.reshape(test_features_extractor.shape[0],-1)

predicted_output = clf.predict(test_feature)
from sklearn.metrics import classification_report
report = classification_report(y_test_2, predicted_output)
print(report)

test_features_extractor = model.predict(X_test_d)
test_feature = test_features_extractor.reshape(test_features_extractor.shape[0],-1)

predicted_output = clf.predict(test_feature)
from sklearn.metrics import classification_report
report = classification_report(y_test_d, predicted_output)
print(report)





"""# Prepare data and train- Classes 21-30"""

X_3 = []
Y_3 = []
#Extract files from folder
def prepareNameWithLabels():
    for i in tqdm(class_label[20:30]):
        sourceFiles=os.listdir(os.path.join(path,i))
        for val in sourceFiles:
            img = imread(os.path.join(path,i, val))
            X_3.append(img)
            Y_3.append(i)

prepareNameWithLabels()

X_3 = np.asarray(X_3)
Y_3 = np.asarray(Y_3)

print(X_3.shape, Y_3.shape)

X_train_3, X_test_3, y_train_3, y_test_3= train_test_split(X_3, Y_3,
                                                            test_size = 0.1,
                                                            stratify = Y_2,
                                                            random_state = 202)
import copy

X_train_d = copy.deepcopy(X_train_3)
y_train_d = copy.deepcopy(y_train_3)
np.random.seed(202)

for i in np.unique(y_train_1):
  idx = np.random.choice(np.where(y_train_1 == i)[0], 40, replace=False)
  X_train_d = np.concatenate([X_train_d, X_train_1[idx]])
  y_train_d = np.concatenate([y_train_d, y_train_1[idx]])


for i in np.unique(y_train_2):
  idx = np.random.choice(np.where(y_train_2 == i)[0], 40, replace=False)
  X_train_d = np.concatenate([X_train_d, X_train_2[idx]])
  y_train_d = np.concatenate([y_train_d, y_train_2[idx]])

print(X_train_2.shape, X_train_d.shape)

X_test_d = np.concatenate([X_test_1, X_test_2, X_test_3])
y_test_d = np.concatenate([y_test_1, y_test_2, y_test_3])

feature_extractor = model.predict(X_train_d)
shape = feature_extractor.shape
feature = feature_extractor.reshape(feature_extractor.shape[0],-1)

clf.partial_fit(feature, y_train_d)
clf.score(feature,y_train_d)

test_features_extractor = model.predict(X_test_3)
test_feature = test_features_extractor.reshape(test_features_extractor.shape[0],-1)

predicted_output = clf.predict(test_feature)
from sklearn.metrics import classification_report
report = classification_report(y_test_3, predicted_output)
print(report)

test_features_extractor = model.predict(X_test_d)
test_feature = test_features_extractor.reshape(test_features_extractor.shape[0],-1)

predicted_output = clf.predict(test_feature)
from sklearn.metrics import classification_report
report = classification_report(y_test_d, predicted_output)
print(report)





"""# Prepare data and train- Classes 31-40"""

X_4 = []
Y_4 = []
#Extract files from folder
def prepareNameWithLabels():
    for i in tqdm(class_label[30:40]):
        sourceFiles=os.listdir(os.path.join(path,i))
        for val in sourceFiles:
            img = imread(os.path.join(path,i, val))
            X_4.append(img)
            Y_4.append(i)

prepareNameWithLabels()

X_4 = np.asarray(X_4)
Y_4 = np.asarray(Y_4)

print(X_4.shape, Y_4.shape)

X_train_4, X_test_4, y_train_4, y_test_4= train_test_split(X_4, Y_4,
                                                            test_size = 0.1,
                                                            stratify = Y_2,
                                                            random_state = 202)
import copy

X_train_d = copy.deepcopy(X_train_4)
y_train_d = copy.deepcopy(y_train_4)
np.random.seed(202)

for i in np.unique(y_train_1):
  idx = np.random.choice(np.where(y_train_1 == i)[0], 40, replace=False)
  X_train_d = np.concatenate([X_train_d, X_train_1[idx]])
  y_train_d = np.concatenate([y_train_d, y_train_1[idx]])


for i in np.unique(y_train_2):
  idx = np.random.choice(np.where(y_train_2 == i)[0], 40, replace=False)
  X_train_d = np.concatenate([X_train_d, X_train_2[idx]])
  y_train_d = np.concatenate([y_train_d, y_train_2[idx]])

for i in np.unique(y_train_3):
  idx = np.random.choice(np.where(y_train_3 == i)[0], 40, replace=False)
  X_train_d = np.concatenate([X_train_d, X_train_3[idx]])
  y_train_d = np.concatenate([y_train_d, y_train_3[idx]])

print(X_train_2.shape, X_train_d.shape)

X_test_d = np.concatenate([X_test_1, X_test_2, X_test_3, X_test_4])
y_test_d = np.concatenate([y_test_1, y_test_2, y_test_3, y_test_4])

feature_extractor = model.predict(X_train_d)
shape = feature_extractor.shape
feature = feature_extractor.reshape(feature_extractor.shape[0],-1)

clf.partial_fit(feature, y_train_d)
clf.score(feature,y_train_d)

test_features_extractor = model.predict(X_test_4)
test_feature = test_features_extractor.reshape(test_features_extractor.shape[0],-1)

predicted_output = clf.predict(test_feature)
from sklearn.metrics import classification_report
report = classification_report(y_test_4, predicted_output)
print(report)

test_features_extractor = model.predict(X_test_d)
test_feature = test_features_extractor.reshape(test_features_extractor.shape[0],-1)

predicted_output = clf.predict(test_feature)
from sklearn.metrics import classification_report
report = classification_report(y_test_d, predicted_output)
print(report)





"""# Prepare data and train- Classes 41-60"""

X_5 = []
Y_5 = []
#Extract files from folder
def prepareNameWithLabels():
    for i in tqdm(class_label[40:60]):
        sourceFiles=os.listdir(os.path.join(path,i))
        for val in sourceFiles:
            img = imread(os.path.join(path,i, val))
            X_5.append(img)
            Y_5.append(i)

prepareNameWithLabels()

X_5 = np.asarray(X_5)
Y_5 = np.asarray(Y_5)

print(X_5.shape, Y_5.shape)

X_train_5, X_test_5, y_train_5, y_test_5= train_test_split(X_5, Y_5,
                                                            test_size = 0.1,
                                                            stratify = Y_5,
                                                            random_state = 202)
import copy

X_train_d = copy.deepcopy(X_train_5)
y_train_d = copy.deepcopy(y_train_5)
np.random.seed(202)

for i in np.unique(y_train_1):
  idx = np.random.choice(np.where(y_train_1 == i)[0], 40, replace=False)
  X_train_d = np.concatenate([X_train_d, X_train_1[idx]])
  y_train_d = np.concatenate([y_train_d, y_train_1[idx]])


for i in np.unique(y_train_2):
  idx = np.random.choice(np.where(y_train_2 == i)[0], 40, replace=False)
  X_train_d = np.concatenate([X_train_d, X_train_2[idx]])
  y_train_d = np.concatenate([y_train_d, y_train_2[idx]])

for i in np.unique(y_train_3):
  idx = np.random.choice(np.where(y_train_3 == i)[0], 40, replace=False)
  X_train_d = np.concatenate([X_train_d, X_train_3[idx]])
  y_train_d = np.concatenate([y_train_d, y_train_3[idx]])

for i in np.unique(y_train_4):
  idx = np.random.choice(np.where(y_train_4 == i)[0], 40, replace=False)
  X_train_d = np.concatenate([X_train_d, X_train_4[idx]])
  y_train_d = np.concatenate([y_train_d, y_train_4[idx]])

print(X_train_2.shape, X_train_d.shape)

X_test_d = np.concatenate([X_test_1, X_test_2, X_test_3, X_test_4, X_test_5])
y_test_d = np.concatenate([y_test_1, y_test_2, y_test_3, y_test_4, y_test_5])

feature_extractor = model.predict(X_train_d)
shape = feature_extractor.shape
feature = feature_extractor.reshape(feature_extractor.shape[0],-1)

clf.partial_fit(feature, y_train_d)
clf.score(feature,y_train_d)

test_features_extractor = model.predict(X_test_5)
test_feature = test_features_extractor.reshape(test_features_extractor.shape[0],-1)

predicted_output = clf.predict(test_feature)

from sklearn.metrics import classification_report
report = classification_report(y_test_5, predicted_output)
print(report)

test_features_extractor = model.predict(X_test_d)
test_feature = test_features_extractor.reshape(test_features_extractor.shape[0],-1)

predicted_output = clf.predict(test_feature)
from sklearn.metrics import classification_report
report = classification_report(y_test_d, predicted_output)
print(report)

